# find the prefer direction
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import normalize as sk_normalize
from scipy.stats import circmean
from core.net_struct.struct_analyzer import Struct_analyzer

class Bump_activity():
    '''analysing the structure of the hidden layer'''
    def fit(self, input_colors, fir_rate, delay_int):
        '''
        input:
          input_colors ([float] (ring_centers)): the input color indicated by degree
          fir_rate ([float] (time_len, ring_centers, rnn_size))
          delay_int ([float] (2)): [delay_start_time, delay_end_time]
        self:
          tuning ([float] (ring_centers, rnn_size)): the tuning curve, each entry present the firing rate.
          label ([float] (rnn_size)): the prefer color for unit i, where i < rnn_size
          t_strength ([float] (larger t means the correspond neuron are more perferent to a particular color))
        '''
        self.input_colors = input_colors
        self.fir_rate = fir_rate 
        self.delay_int = delay_int
        self._prefer_color()

    def _prefer_color(self):
        '''
        find the tuning curve and the prefer color of each neuron. Circular weighted mean is used. See the detail in the method of https://doi.org/10.1038/nn.3645

        input:
          input_colors ([float] (ring_centers)): the input color indicated by degree
          fir_rate ([float] (time_len, ring_centers, rnn_size))
          delay_int ([float] (2)): [delay_start_time, delay_end_time]
        self:
          tuning ([float] (ring_centers, rnn_size)): the tuning curve, each entry present the firing rate.
          label ([float] (rnn_size)): the prefer color for unit i, where i < rnn_size
          t_strength ([float] (larger t means the correspond neuron are more perferent to a particular color))
        '''
        fir_rate_delay = self.fir_rate[self.delay_int[0]:self.delay_int[1], :, :]
        self.tuning = np.mean(fir_rate_delay, axis = 0) # mean over the delay period

        # calculate the preference color
        self.label = []
        self.t_strength = []
        for j in range(self.tuning.shape[1]): # loop over all neurons
            pref_angle, norm = circular_mean(self.tuning[:, j], self.input_colors)
            self.label.append(pref_angle)
            self.t_strength.append(norm)

        self.label = np.array(self.label)
        self.t_strength = np.array(self.t_strength)

    def thre_weak_tuning(self, mat, thre=-1):
        '''
        delete non preference neurons
        input:
          mat ([float] (n, num_neurons), or [float] (num_neurons) ): n can be any interger larger than 0. the num_neurons must be the same with length of label.
        output:
          mat_cut ([float] (n, num_neurons_cut) or [float] (num_neurons_cut) ): num_neurons_cut is the number of neurons which is stronger than the threshold
        '''
        strong_t = self.t_strength > thre

        if len(mat.shape) == 1:
            mat_cut = mat[strong_t]
        elif len(mat.shape) == 2:
            mat_cut = mat[:, strong_t]

        return mat_cut

    def reorder_prefer(self, mat, label):
        '''
        reordering mat accoring the the label

        input:
          mat ([float] (n, rnn_size)): reordering the tensor according to the find axis, so that mat[,,,0] indicate the features of neuron has preference in self.input_colors[0]
        output:
          label_sorted:
          mat_sorted: same shape as above
        '''
        order = np.argsort(label)
        mat_soted = mat[:, order]
        label_sorted = label[order]
        return mat_soted, label_sorted

    def norm_fir(self, mat, tuning):
        '''
        normalize firing rate with every cell's tuning curve
        input:
          mat ([float] (n, num_neurons)): n could be any number
          tuning ([float] (n_color, num_neurons)): the tuning curve of those neurons. This matrix can be generated by _prefer_color()
        '''
        norm = np.sum( np.abs(tuning), axis=0 )
        mat_norm = mat / norm
        return mat_norm

def circular_mean(weights, angles):
    weight_norm = weights / np.sum(weights)
    x = np.dot(np.cos(np.radians(angles)) , weight_norm)
    y = np.dot(np.sin(np.radians(angles)) , weight_norm)

    mean = np.degrees(np.arctan2(y, x)) % 360 # set to positive
    norm = np.linalg.norm([x, y])
    return mean, norm

def bump_pipline(bump, fir_rate, thre=0.30, bin_width=5):
    '''
    This function process fir_rate. The fir_rate must be generated from the same model that is fitted
    1. cut the weak tuned neurons.
    2. sort neurons by the order of preferential color.
    3. normalize the fir_rate according to the tuning curve.
    input:
      bump: fitted bump_activity class
      fir_rate ([float] (n, num_neurons))
    output:
      processed fir_rate along with the its preference label
    '''
    ### cut
    tuning_cut = bump.thre_weak_tuning(bump.tuning, thre=thre)
    label_cut = bump.thre_weak_tuning(bump.label, thre=thre)
    fir_rate_cut = bump.thre_weak_tuning(fir_rate, thre=thre)

    ### reorder
    tuning_sort, label_sort = bump.reorder_prefer(tuning_cut, label_cut)
    fir_rate_sort, label_sort = bump.reorder_prefer(fir_rate_cut, label_cut)

    #### normalization
    #fir_rate_pped = bump.norm_fir(fir_rate_sort, tuning_sort)
    if bin_width is None:
        fir_rate_pped, label_bin = fir_rate_sort, label_sort
    else:
        fir_rate_pped, label_bin = bin_fir(fir_rate_sort, label_sort, bin_width)

    return fir_rate_pped, label_bin

def sc_dist(bump, w_hh, thre=0.30, bin_width=5):
    '''
    This function process fir_rate. The fir_rate must be generated from the same model that is fitted
    1. cut the weak tuned neurons.
    2. sort neurons by the order of preferential color.
    input:
      bump: fitted bump_activity class
      w_hh ([float] (num_neurons, num_neurons))
    output:
      processed w_hh along with the its preference label
    '''
    ### cut
    tuning_cut = bump.thre_weak_tuning(bump.tuning, thre=thre)
    label_cut = bump.thre_weak_tuning(bump.label, thre=thre)
    w_hh_cut = bump.thre_weak_tuning(w_hh, thre=thre)
    w_hh_cut_T = bump.thre_weak_tuning(np.transpose(w_hh_cut), thre=thre)
    w_hh_cut = np.transpose(w_hh_cut_T)


    ### reorder
    tuning_sort, label_sort = bump.reorder_prefer(tuning_cut, label_cut)
    w_hh_sort, label_sort = bump.reorder_prefer(w_hh_cut, label_cut)
    w_hh_sort, label_sort = bump.reorder_prefer(np.transpose(w_hh_sort), label_cut)
    w_hh_sort = np.transpose(w_hh_sort)

    if bin_width is None:
        w_hh_pped, label_bin = w_hh_sort, label_sort
    else:
        w_hh_pped, label_bin = bin_fir(w_hh_sort, label_sort, bin_width)
        w_hh_pped, label_bin = bin_fir(np.transpose(w_hh_pped), label_sort, bin_width)
        w_hh_pped = np.transpose(w_hh_pped)

    return w_hh_pped, label_bin

def bin_fir(fir_rate, label, bin_width):
    '''
    use mean firing rate to replace neurons in the same bin, so that this firing rate is homogeniously distributed across all colors by n bins
    input:
      fir_rate ([float] (n, num_neurons))
      label ([float] (num_neurons))
      bin_width (int): if its 5 then the neuron label would be its example [0, 5, 10, ..., 355]
    output:
      fir_rate_bin ([float] (n, n_bin)): where n_bin = 360 / bin_width
      label_bin ([float] (n_bin)): example [2.5, 7.5, 12.5, ..., 357.5]
    '''

    label_bin = np.arange(0, 360, bin_width)
    label_bin_ex = np.append(label_bin, [360])
    n_bin = len(label_bin)
    fir_rate_bin = np.zeros((fir_rate.shape[0], n_bin))
    for i in range(len(label_bin)):
        col_idx = (label < label_bin_ex[i + 1]) * (label > label_bin_ex[i])
        fir_rate_bin[:, i] = np.mean( fir_rate[:, col_idx], axis=1 )

    #fir_rate_bin = np.nan_to_num(fir_rate_bin, np.mean(np.mean(fir_rate_bin)))

    #if np.any( np.isnan(fir_rate) ):
    #    print('nan occur in fir')
    #if np.any( np.isnan(fir_rate_bin) ):
    #    print('nan occur in fir bin', col_idx)
    label_bin = label_bin + bin_width / 2 # use the center

    return fir_rate_bin, label_bin


def tuning_curve(sub, delay, input_colors, tuned_thre=-999, batch_size = 1, bin_width=6):
    '''
    mean firing rate of neurons in the delay period
    input:
    sub (Agent class): contain one RNN
    delay (float): delay time length
    input_colors (array [float] (m)): should cover the color from 0 to 360.
    tuned_thre (float): ignore the neurons has no response to the input.
    output:
    tuning_pped (array [float] (m * n)): m is the input_colors, n is the number of neurons, which has prefered color labeled by label
    label (array [float] (n)): prefer color
    '''
    n_colors = len(input_colors)
    sigma_rec=0; sigma_x = 0;
    label_method = 'rnn_decoder'
    nan_method='remove'

    str_ana = Struct_analyzer()
    str_ana.read_rnn_agent(sub)
    str_ana.prepare_label(n_colors=n_colors, sigma_rec=sigma_rec, sigma_x=sigma_x, batch_size=batch_size, prod_intervals=delay, method=label_method, bin_width_color=bin_width, nan_method=nan_method)
    tuning, neuron_label, color_label = str_ana.output_tuning(bin_width_color=bin_width, bin_width_neuron=bin_width) # show tuning matrix for each rnn
    return tuning, neuron_label.flatten()
