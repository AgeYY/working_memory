"""Collections of tasks."""

from __future__ import division
import numpy as np
import math
import sys
from .color_manager import Degree_color
from .color_input import Color_input


class Color_task():
    # generate trial for color task
    def __init__(self, config, kwargs):
        '''
    kwargs:
      bias_centers (array(float)): in nature scene, the input color should be biased. the unit is degree
      batch_size (int): the batch_size of the dataset
      ##### please modify config in default.py
      config['dt'] (float): default time steps, please use 20 ms
      config['rng']: random generator
      config['pulse_duration']: duration of input pulse
      config['response_duration']: duration of response
      config['bias_centers'] (np.array[float]): bias centers
      config['n_degree'] (int): 0, 360 will be sampled evenly into n_degree samples as the input
      config['sig'] (float): width of centers. In the gaussian case this would be the standard deviation, in the delta case this would be the width of the rect
      config['center_prob'] (float): in the delta case. There was a 50% chance (defaule) that the color of that sample would be drawn from a biased dis- tribution
      prod_interval (array [float (2)]): production interval with unit ms
        '''
        # explicit the parameters
        self.config = config.copy(); self.kwargs = kwargs
        self.dt = config['dt']
        self.rng = config['rng']
        self.pulse_duration = int(config['pulse_duration']/self.dt)
        self.pulse_duration_go = int(config['pulse_duration_go']/self.dt)
        self.response_duration = int(config['response_duration']/self.dt)
        self.bias_centers = config['bias_centers']
        self.n_degree = config['n_degree']
        self.batch_size = kwargs['batch_size']
        self.prod_interval = config['prod_interval']

    def gen_color_deg(self, mode):
        '''
        generate input color in the unit of degree.
        mode (str):
          'test' -- generated by self.sampled_degree in __init__
          others -- by self.bias_method
        '''
        ########## Generate input color in degree
        color_input = Color_input()
        color_input.add_samples(self.n_degree)

        if (mode == 'random') or (mode == 'random_validate'):  # Randomly generate parameters
            self.prod_interval = (self.rng.uniform(self.prod_interval[0], self.prod_interval[1], self.batch_size)/self.dt).astype(int)
            color_input.prob(self.bias_centers, method=self.config['bias_method'], sig=self.config['sig'], center_prob=self.config['center_prob'])
            self.sampled_degree = color_input.out_color_degree(self.batch_size, random_state=self.rng)

        elif mode == 'test':
            ##### self-defined interval
            self.prod_interval = self.kwargs['prod_interval']
            if not hasattr(self.prod_interval, '__iter__'):
                self.prod_interval = np.array([self.prod_interval] * self.batch_size)
            self.prod_interval = (self.prod_interval / self.dt).astype(int)
            self.sampled_degree = self.kwargs['sampled_degree']
        else:
            raise ValueError('Unknown mode: ' + str(mode))
        return self.sampled_degree

    def _encode_color_cell(self, num_unit):
        '''
        encoding color with color cell method
        '''
        from core.color_manager import Color_cell
        ccell = Color_cell(num_unit)
        self.sampled_color_encoded = ccell.fire(self.sampled_degree)
        self.n_input = num_unit+1; self.n_output = num_unit # +1 is for go cue

    def encode_deg(self, encode_method):
        '''
        encode_method (str): LMS or color_cell_32 please see the color_manager.py
        '''
        if encode_method == 'LMS':
            deg_color = Degree_color()
            self.sampled_color_encoded = deg_color.out_color(self.sampled_degree, fmat='LMS') 
            self.n_input = 3 + 1; self.n_output = 3

        elif encode_method == 'color_cell_32':
            num_unit = 32
            self._encode_color_cell(num_unit)
        elif encode_method == 'color_cell_unit':
            num_unit = self.config['num_unit']
            self._encode_color_cell(num_unit)

        elif encode_method == 'triangular':
            from core.color_manager import Color_triangular
            ctri = Color_triangular()
            self.sampled_color_encoded = ctri.fire(self.sampled_degree)
            self.n_input = 2 + 1; self.n_output = 2

    def gen_trial(self):
        ########## Expand input to time series
        # the onset time of the first stimulus
        stim1_on = (self.rng.uniform(100, 100, self.batch_size)/self.dt).astype(int)

        # the offset time of the first stimulus
        stim1_off = stim1_on + self.pulse_duration
        # the onset time of the go cue
        control_on = stim1_off + self.prod_interval
        # the offset time of the go cue
        control_off = control_on + self.pulse_duration_go
        # response start time
        response_on = control_off
        # response end time
        response_off = response_on + self.response_duration
        xtdim = response_off

        trial = Trial(self.config, xtdim.max(), self.batch_size)
        for i in range(self.n_input - 1):
            trial.add('input', i, ons=stim1_on, offs=stim1_off, strengths=self.sampled_color_encoded[:, i])
            trial.add('out', i, ons=response_on, offs=response_off, strengths=self.sampled_color_encoded[:, i])
        trial.add('input', i + 1, ons=control_on, offs=control_off, strengths=trial.expand(1.)) # the last input channel is go cue

        trial.cost_mask = np.zeros((xtdim.max(), self.batch_size, 1), dtype=trial.float_type)
        trial.add('cost_mask', 0, ons=stim1_on, offs=response_off, strengths=trial.expand(1.))

        trial.epochs = {'fix': (None, stim1_on),
                    'stim1': (stim1_on, stim1_off),
                    'interval': (stim1_off, control_on),
                    'go_cue': (control_on, control_off),
                    'go': (control_off, response_on),
                    'response': (response_on, response_off)}

        trial.prod_interval = self.prod_interval
        trial.sampled_degree = self.sampled_degree
        trial.seq_len = xtdim
        trial.max_seq_len = xtdim.max()
        return trial

def color_reproduction_delay_tri(config, mode, **kwargs):
    ctask = Color_task(config, kwargs)
    ctask.gen_color_deg(mode)
    ctask.encode_deg('triangular')
    return ctask.gen_trial()

def color_reproduction_delay_cones(config, mode, **kwargs):
    ctask = Color_task(config, kwargs)
    ctask.gen_color_deg(mode)
    ctask.encode_deg('LMS')
    return ctask.gen_trial()

def color_reproduction_delay_32(config, mode, **kwargs):
    ctask = Color_task(config, kwargs)
    ctask.gen_color_deg(mode)
    ctask.encode_deg('color_cell_32')
    return ctask.gen_trial()

def color_reproduction_delay_unit(config, mode, **kwargs):
    '''
    similar to color_reproduction_delay_32, but the size of input is changable
    '''
    ctask = Color_task(config, kwargs)
    ctask.gen_color_deg(mode)
    ctask.encode_deg('color_cell_unit')
    return ctask.gen_trial()


# map string to function
rule_mapping = {
                'color_reproduction_delay_32': color_reproduction_delay_32,
                'color_reproduction_delay_cones': color_reproduction_delay_cones,
                'color_reproduction_delay_tri': color_reproduction_delay_tri,
                'color_reproduction_delay_unit': color_reproduction_delay_unit,
                }

def generate_trials(rule, hp, mode, noise_on=True, **kwargs):
    """Generate one batch of data.

    Args:
        hp: dictionary of hyperparameters
        mode: str, the mode of generating. Options: random, test, psychometric
        noise_on: bool, whether input noise is given

    Return:
        trial: Trial class instance, containing input and target output
    """
    # print(rule)
    config = hp
    kwargs['noise_on'] = noise_on
    trial = rule_mapping[rule](config, mode, **kwargs)

    if noise_on:
        trial.add_x_noise()

    return trial


#def get_dist(original_dist):
#    '''Get the distance in periodic boundary conditions'''
#    return np.minimum(abs(original_dist), 2*np.pi-abs(original_dist))


# generating values of x, y, c_mask specific for tasks
# config contains hyper-parameters used for generating tasks
class Trial(object):
    """Class representing a batch of trials."""

    def __init__(self, config, xtdim, batch_size):
        """A batch of trials.

        Args:
            config: dictionary of configurations
            xtdim: int, number of total time steps
            batch_size: int, batch size
        """
        self.float_type = 'float32'  # This should be the default
        self.config = config
        self.dt = self.config['dt']

        self.n_input = self.config['n_input']
        self.n_output = self.config['n_output']

        self.batch_size = batch_size
        self.xtdim = xtdim

        # time major
        self.x = np.zeros((xtdim, batch_size, self.n_input), dtype=self.float_type)
        self.y = np.zeros((xtdim, batch_size, self.n_output), dtype=self.float_type)
        self.cost_mask = np.zeros((xtdim, batch_size, self.n_output), dtype=self.float_type)
        # strength of input noise
        self._sigma_x = config['sigma_x'] * math.sqrt(2./self.config['alpha'])

    def expand(self, var):
        """Expand an int/float to list."""
        if not hasattr(var, '__iter__'):
            var = [var] * self.batch_size
        return var

    def add(self, loc_type, loc_idx, ons, offs, strengths, gaussian_center=None, noise=False):
        """Add an input or stimulus output to the indicated channel.

        Args:
            loc_type: str type of information to be added
            loc_idx: index of channel
            ons: int or list, index of onset time
            offs: int or list, index of offset time
            strengths: float, strength of input or target output
        """

        if loc_type == 'input':
            for i in range(self.batch_size):
                self.x[ons[i]: offs[i], i, loc_idx] = strengths[i]

        elif loc_type == 'out':

            for i in range(self.batch_size):
                self.y[ons[i]: offs[i], i, loc_idx] = strengths[i]

        elif loc_type == 'cost_mask':

            for i in range(self.batch_size):
                self.cost_mask[ons[i]: offs[i], i, loc_idx] = strengths[i]

        else:
            raise ValueError('Unknown loc_type')

    def add_x_noise(self):
        """Add input noise."""
        self.x += self.config['rng'].randn(*self.x.shape) * self._sigma_x
